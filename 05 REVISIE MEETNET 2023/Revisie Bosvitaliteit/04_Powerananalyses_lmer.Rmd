# Poweranalyes via een mixed effect model

## Model jaar per jaar

In eerste instantie willen we zien welke verschil het huidige meetnet kan aantonen tussen 2 opeenvolgende jaren. Hiervoor gaan we uit van een dataset met circa 75 plots met 20 bomen per plot.

### Op de volledige dataset

```{r, cache = TRUE, fig.cap = "verdeling variaties data in opeenvolgende jaren. Rode lijn is de gekozen parameter voor de simulaties."}
modeljpj <- NULL
for (i in 1995:2021) {
modeljpj[[i-1994]] <- lmer(nnv ~ factor(Jaar) + (1|PlotNr/BoomNr), 
                 data = df_trees %>% filter(Jaar %in% c(i,i+1) ))  
}
sd_plot <- sapply(modeljpj, function(x) sqrt(VarCorr(x)$PlotNr[1,1]))
sd_tree <- sapply(modeljpj, function(x) sqrt(VarCorr(x)$`BoomNr:PlotNr`[1,1]))
sd_resi <- sapply(modeljpj, function(x) attr(VarCorr(x), "sc"))


ggplot(data = bind_rows(data.frame(type = "plot", 
                                   sd = sd_plot, 
                                   chosen = ceiling(median(sd_plot)*100)/100),
                        data.frame(type = "tree", 
                                   sd = sd_tree,
                                   chosen = ceiling(median(sd_tree)*100)/100),
                        data.frame(type = "resi", 
                                   sd = sd_resi,
                                   chosen = ceiling(median(sd_resi)*100)/100)), 
       aes(x = sd)) + 
  geom_histogram(bins = 20) + 
  geom_vline(aes(xintercept = chosen), 
             color = "red") + 
  facet_wrap(~type, ncol = 1)

#sd_plot = 0.07
#sd_tree = 0.09
#sd_resi = 0.07
```


### Op geaggregeerde dataset

```{r jpjagg}
modeljpj <- NULL
for (i in 1995:2021) {
  modeljpj[[i-1994]] <- 
    lmer(nnv ~ factor(Jaar) + (1|PlotNr), 
         data = df_trees_agg %>% filter(Jaar %in% c(i,i+1)))  
}
sd_plot <- sapply(modeljpj, function(x) sqrt(VarCorr(x)$PlotNr[1,1]))
sd_resi <- sapply(modeljpj, function(x) attr(VarCorr(x), "sc"))


ggplot(data = bind_rows(data.frame(type = "plot", 
                                   sd = sd_plot, 
                                   chosen = ceiling(median(sd_plot)*100)/100),
                        data.frame(type = "resi", 
                                   sd = sd_resi,
                                   chosen = ceiling(median(sd_resi)*100)/100)), 
       aes(x = sd)) + 
  geom_histogram(bins = 20) + 
  geom_vline(aes(xintercept = chosen), 
             color = "red") + 
  facet_wrap(~type, ncol = 1)

#sd_plot = 0.06
#sd_resi = 0.03
```



```{r jpjpwr, cache = TRUE}

datajpj <- read_csv2('data/power_jpj.csv')

ggplot(datajpj, aes(x = jaarlijkse_trend, y = jaarlijkse_power)) + 
  geom_point() + geom_line() + geom_hline(yintercept = 0.80, color = "red")
  
```
De berekeningen gebeuren in het script _*simulaties_jpj.R*_
Een trend van ongeveer 0.12 kan aangetoond worden met 80% power. Dat wil zeggen dat een bladverlies die stijgt van 0.25 naar 0.262 aangetoond (ofwel een stijging van 5%) kan worden aangetoond tussen 2 verschillende jaren.


## Berekening power op de geaggregeerde dataset voor een langere periode

Instelvariabelen: 

- Standaarddeviatie tussen plots is `0.07`, dus 0.05, 0.07 en 0.09 worden bekeken
- Standaarddeviatie tussen  bomen in een plot is `0.175`, en varieert weinig, dus blijft behouden
- Aantal plots is 20,40,60,80,100,120
- Aantal bomen is 5, 10, 15, 20 of 25, de standaarddeviatie tussen bomen wordt omgezet door de standaardfout op het plotgemiddelde door deze standaarddeviatie te delen door de vierkantswortel van het aantal bomen.
- De standaardeviatie van de trend per plot is `0.065` en varieert tussen 0.04 en 0.09
- De correlatie tussen trend en intercept per plot is `0.20`, en we zullen dit instellen op 0.00, 0.20 en 0.40.
- De verschillende trends die we willen zien is 6,12,18 of 24 procent op 12 jaar en 5, 10, 15 en 20 procent op 20 jaar.

Als basis zal ik werken met 12% op 12 jaar, dus de verschillende instelvariabelen van iedere variabele wordt enkel in dat scenario bekeken.
De verschillende trends wordten bekeken op de basisinstelvariabelen en niet op de varianten daarop.

### Kracht met de huidige steekproef

Deze powerberekeningen gebeuren op basis van een extern R script, die als aparte scripts bij het document gevoegd worden.

```{r simrfixedvars, fig.cap="Powerberekening voor de berekende instelvariabelen voor 20 tot 120 proefvlakken voor detectie van 12% op 12 jaar en 20% op 20 jaar"}
powers1 <- read_csv2('data/modelsim_fixed.csv')
ggplot(powers1, 
       aes(x = N_plots, y = power, ymin = lcl, ymax = ucl,
           color = factor(N_years))) + 
  geom_point() + geom_line(linetype = "dashed") +  geom_errorbar() +
  geom_hline(yintercept = 0.8, color = "green4") + 
  labs(x = "Aantal plots", y = "Kracht", color = "Jaren") + 
  scale_y_continuous(labels = scales::percent)
```

Uit figuur \@ref(fig:simrfixedvars) blijkt dat de huidige dataset volstaat voor een trend van 20% over een periode van 20 jaar te vinden, maar met  deze resultaten moeten wel voorzichtig omgesprongen worden, want de invloed van de instelvariabelen is groot. 
Het lijkt bijzonder dat er weinig verschil is in power tussen een periode van 12 jaar om 12% verschil te detecteren en een periode van 20 jaar om een verschil van 20% te detecteren.
Hier ligt dit vermoedelijk door het gebruik van een random helling op jaar, dus over een langere periode zal ook de random helling leiden tot grotere verschillen tussen de plots. Indien geen random helling in het model wordt opgenomen dan blijkt duidelijk dat 20% over 20 jaar veel gemakkelijker gedetecteerd wordt dan 12% op 12 jaar.
Om een correcte analyse te hebben zou de random helling ook eens op 20 jaar moeten berekend worden, en hier zal vermoedelijk het effect van deze helling een stuk kleiner zijn, en dus de steekproef veel krachtiger zijn. <<<Uit de gegevens blijkt dat op 20 jaar de standaarddeviatie op de trend nog ongeveer 0.005 is in plaats van 0.0065.Toch is dit niet overtuigend>>>



### Invloed van instelvariabelen op de power

```{r rsiminstelvarstrees, fig.cap = "Power in functie van het aantal opgemeten bomen per plot. De referentie is de power voor 80 proefvlakken met 20 bomen per proefvlak.}
powers2 <- read_csv2("data/modelsim_var.csv")

ggplot(powers2 %>% filter(Mtype %in% c("Fix", "Var_tree")), 
        aes(x = N_trees, y = power, ymin = lcl, ymax = ucl, 
            color = Mtype == "Fix")) + 
  geom_point() + geom_errorbar() + 
  labs(x = "Aantal bomen", y = "Power", color = "Referentie")


```

Het aantal bomen in de steekproef heeft impact op de variabiliteit op het gemiddeld bladverlies per plot. Minder bomen opmeten betekent meer onzekerheid op dat gemiddelde en een lagere power.

De verplaatsing naar ieder proefvlak is de meest doorslaggevende factor in de tijd die het duurt om een meetnet op te meten. Het bladverlies inschatten voor iedere boom vergt ook redelijk wat tijd, maar het verminderen van de bomen kan een beperkte tijdsbesparking opleveren, maar de vraag is of het waard is om niet meer te houden aan de protocolafspraken voor deze vrij beperkte tijdswinst.


```{r rsiminstelvarstrend, fig.cap = "Power in functie van de te detecteren trend, gebaseerd op een basiswaarde van 25% bladverlies per proefvlak. 12% op 12 jaar komt overeen met een trend van 0.0025 per jaar, 24% op 12 jaar komt overeen met een trend van 0.0050 per jaar. De steekproef bestaat hier uit 80 proefvlakken met 20 bomen per proefvlak.}

ggplot(powers2 %>% filter(Mtype %in% c("Fix", "Var_trend")), 
       aes(x = trend, y = power, ymin = lcl, ymax = ucl, 
           color = Mtype == "Fix")) + 
  geom_point() + geom_errorbar() + 
  labs(x = "Te detecteren trend (12% op 12 jaar of 24% op 12 jaar)", 
       y = "Power", color = "Referentie")

```

Zoals verwacht heeft de te detecteren trend een heel grote invloed op de kracht. Hoe groter het effect is dat ten minste gedetecteerd moet worden, hoe meer kans en dus kracht dat het model dit effect zal kunnen detecteren.

```{r rsiminstelvarsbp, fig.cap = "Power in functie van hoe groot de variatie tussen de verschillende proefvlakken is. Ook hier vertrekken we van een steekproef van 80 proefvlakken met 20 bomen per proefvlak"}

ggplot(powers2 %>% filter(Mtype %in% c("Fix", "Var_bp")), 
       aes(x = sd_bp, y = power, ymin = lcl, ymax = ucl, 
           color = Mtype == "Fix")) + 
  geom_point() + geom_errorbar() + 
  labs(x = "variatie (stdev) tussen verschillende proefvlakken", 
       y = "Power", color = "Referentie")

```

Hoe groot de variatie is tussen de plots heeft ook een impact op de power, maar is heel verwaarloosbaar. Het is ook onduidelijk in welke richting dit invloed heeft, langs de ene kant is er meer variatie dus verwacht je een lagere power, langs de andere kant heeft ieder plot meer informatie, zeker omdat er per plot ook nog een random helling aanwezig is. In bovenstaande figuur lijkt meer variatie contra-intuïtief te leiden tot een hogere power.

```{r rsiminstelvarscor, fig.cap = "Power in functie van hoe groot de correlatie is tussen de inschatting van de random intercept en random slope van het model. Ook hier vertrekken we van een steekproef van 80 proefvlakken met 20 bomen per proefvlak"}

ggplot(powers2 %>% filter(Mtype %in% c("Fix", "Var_cor")), 
       aes(x = cor_is, y = power, ymin = lcl, ymax = ucl, 
           color = Mtype == "Fix")) + 
  geom_point() + geom_errorbar() + 
  labs(x = "Correlatie tussen random intercept van ieder plot en random helling van ieder plot", 
       y = "Power", color = "Referentie")
```

De correlatie tussen intercept en helling op tijd, lijkt een verwaarloosbare invloed te hebben op de power in de huidige setup.

```{r rsiminstelvarssdstrend, fig.cap = "Power in functie van hoe groot de variatie op de trend is tussen de verschillende proefvlakken. Ook hier vertrekken we van een steekproef van 80 proefvlakken met 20 bomen per proefvlak"}

ggplot(powers2 %>% filter(Mtype %in% c("Fix", "Var_sdt")), 
       aes(x = sd_trend, y = power, ymin = lcl, ymax = ucl, 
           color = Mtype == "Fix")) + 
  geom_point() + geom_errorbar() + 
  labs(x = "Random variatie van de helling per plot (stdev)", 
       y = "Power", color = "Referentie")
```

Deze invloed van de random variatie van de trend per plot heeft een gigantische impact op de power. Hoe meer ieder plot een andere trend volgt, hoe lager de power om een specifieke trend te detecteren. 


<!---
## Model jaar per jaar

Een eerste stap is om te onderzoeken welk effect de huidige dataset circa 75 plots met 20 bomen per plot kan detecteren tussen 2 opeenvolgende jaren.

```{r, cache = TRUE, fig.cap = "verdeling variaties data in opeenvolgende jaren. Rode lijn is de gekozen parameter voor de simulaties.}
modeljpj <- NULL
for (i in 1995:2021) {
modeljpj[[i-1994]] <- lmer(nnv ~ factor(Jaar) + (1|PlotNr/BoomNr), 
                 data = df_trees %>% filter(Jaar %in% c(i,i+1) ))  
}
sd_plot <- sapply(modeljpj, function(x) sqrt(VarCorr(x)$PlotNr[1,1]))
sd_tree <- sapply(modeljpj, function(x) sqrt(VarCorr(x)$`BoomNr:PlotNr`[1,1]))
sd_resi <- sapply(modeljpj, function(x) attr(VarCorr(x), "sc"))


ggplot(data = bind_rows(data.frame(type = "plot", 
                                   sd = sd_plot, 
                                   chosen = ceiling(median(sd_plot)*100)/100),
                        data.frame(type = "tree", 
                                   sd = sd_tree,
                                   chosen = ceiling(median(sd_tree)*100)/100),
                        data.frame(type = "resi", 
                                   sd = sd_resi,
                                   chosen = ceiling(median(sd_resi)*100)/100)), 
       aes(x = sd)) + 
  geom_histogram(bins = 20) + 
  geom_vline(aes(xintercept = chosen), 
             color = "red") + 
  facet_wrap(~type, ncol = 1)

#sd_plot = 0.07
#sd_tree = 0.09
#sd_resi = 0.07
```

Het model dat gebruikt wordt voor de  jaar op jaaranalyse is: 

$$
  Bladverlies \sim Jaar + (1|PlotNr/BoomNr)
$$

Onderstaande figuur toont de power voor het geval 10 of 20 bomen per plot gebruikt worden voor 10,25,50,75,100 plots

```{r powerjpj}
pwr_jpj <- readRDS(file.path("output", "simresult_jpj_200.RDS")) 
ggplot(pwr_jpj, aes(x = effect, y = mean, color = factor(plots), 
                    ymin = lower, ymax = upper)) + 
  geom_point() + geom_errorbar() + facet_wrap(~trees, ncol = 1)

```

-->




<!---
## Poweranalyse op de volledige dataset via een random effect model

```{r readsims}

scenarios <- read_csv2("scenarios_01_definition.csv")
files <- list.files("output",  pattern = "power", full.names = TRUE)
powers <- pwrlist <- NULL
for (file in files) {
  start <- regexpr("\\_NR\\_", file) + 4
  end <- regexpr("\\.RDS", file) - 1
  NR <- as.numeric(substring(file, start, end))
  pwrdata <- readRDS(file)
  pwr <- 100 * mean(pwrdata$pval <= 0.05)
  powers <- bind_rows(powers, 
                      cbind(NR = NR, 
                            power = binom::binom.confint(x = sum(pwrdata$pval < pwrdata$alpha), 
                                                         n = pwrdata$n, 
                                                         methods = "exact")))
  pwrlist[[NR]] <- pwrdata
}
scenario_power <- scenarios %>% 
  mutate(NR = as.numeric(NR)) %>%  
  left_join(powers, by = "NR")
```

```{r powerploteffect, echo = FALSE, fig.cap = "Impact op de power van het aantal plots en de standaardafwijking tussen de bomen (als proxy voor het aantal bomen, waar een kleinere sd betekent dat er meer bomen zijn, al werden de simulaties uitgevoerd met telkens 5 bomen)."}

#standard varying plots and sd_tree
ggplot(data = scenario_power %>% filter(NR %in% 1:12), 
       mapping = aes(x = plots, y=power.mean, color = factor(round(sd_tree,3)), 
                     ymin = power.lower, ymax = power.upper)) +
  geom_point() + geom_line() + geom_errorbar() + 
  labs(x = "aantal plots", y = "power", color = " stdev tussen bomen" )
```

De toename van het aantal plots is zoals verwacht heel sterk afhankelijk van het aantal plots, de standaardeviatie tussen de bomen hebben daarentegen een veel kleiner effect, waardoor die bijna volledig overlappen met elkaar, en zelfs soms door toeval verbetering brengen met kleinere stdev.


```{r powerothereffects, echo = FALSE, fig.cap = "Vergelijking van de impact op de power voor verschillende scenario's, in vergelijking met het referentiescenario van 75 plots."}
#varying other variables, keeping plots fixed at 75
#make a ribbon for the reference, so everything is comparable
ggplot(data = scenario_power %>% filter(!is.na(Desc2)), 
       mapping = aes(x = Desc2, 
                     y= power.mean, 
                     color = Desc2, 
                     ymin = power.lower, 
                     ymax = power.upper)) +
  geom_rect(xmin = 0, ymin = scenario_power$power.lower[1],
            xmax = 9, ymax = scenario_power$power.upper[1], 
            alpha = 0.1, 
            color = inbo_palette()[2], 
            fill = inbo_palette()[2]) +
  geom_vline(xintercept = 2.5) + 
  geom_point() + 
  geom_errorbar() + 
  scale_x_discrete(labels = sprintf("%02d", 1:8)) + 
  labs(color = "Description", x = "Scenario", y = "Power" )



```

In figuur \@ref(fig:powerothereffects) zijn verschillende scenario's vergeleken met 

het referentiescenario. Het referentiescenario is hetgeen het dichtste aansluit bij het bestaande meetnet.

Links van de blauwe lijn zie je de power voor 25 plots voor 20 bomen en 5 bomen, waarbij alle andere variabelen gelijk zijn gehouden. Het verviervoudigen van het aantal bomen leidt tot een hoger power.

De grootste effecten op de power van het meetnet zijn hoe variabel de trend is tussen de verschillende plots, iets waar we niet echt veel controle op hebben, en het verhogen van het te verwachten detecteren effect. Een dubbele trend dan de vooropgestelde trend van 12% op 12 jaar, zorgt dat het meetnet met de ingestelde parameters bijna altijd dit effect zal kunnen detecteren met het huidige meetnet.

Een lagere variatie tussen de baseline vitaliteit van de plots en een lagere correlatie tussen de random intercept en trend - dit betekent dat deze minder afhankelijk zijn en dus elk meer verklaren -, kunnen de power gunstig beïnvloeden.

In bovenstaande figuur is de power iets hoger indien een hogere residuele variantie. Dit is niet logisch, dus moet nader onderzocht worden, maar doordat er al heel veel variatie door de andere termen in het model verklaard wordt, is het mogelijk dat de residuele variatie niet veel verschil meer maakt. Het is natuurlijk ook wat artificieel, want met een hogere residuele variatie, wordt ook impact verwacht op de random slope en intercept op het plot niveau <<<NADER ONDERZOEKEN>>>

--->


<!---

## Berekenen kostenefficiëntie

Voorlopig kunnen per dag 2 plots bezocht worden, wat leidt tot ongeveer 40 mensdagen veldwerk per jaar.

De belangrijkste kosten

- Inzet werknemer voor rapportage
- Inzet werknemer voor veldwerk
- Transport tussen plots
- In mindere mate: materiaal

Vanuit gaande van volgende parameters:

- Gemiddelde rijtijd per dag : 
    - pendeltijd: 120 minuten *pendel*
    - afstand naar volgend plot: 50 minuten  *plottransp*
- Gemiddelde rij-afstand per dag: 225 kilometer (9000km voor 75 plots, 2 plots per dag)
- Wandelen naar de correcte plaats in een plot: 15 minuten *zoek*
- Gemiddelde tijd om het bladverlies te evalueren van een boom: 5 minuten *nnv*
- Gemiddelde tijd om andere symptomen en omtrek te evalueren: 2 minuten *sympt*
- Gemiddeld aantal bomen per plot: 21 *trees*
- Plots per dag *ppd*
- Maximale tijd per dag: 10 uur *maxtpd*

Tijd op het terrein per plot *terrein*: zoek + (nnv + sympt) * trees
Transport naar een plot *trans*: pendel/ppd + plottransp * (ppd - 1)
totale tijd: 75 plots * (terrein + trans)

Vuistregel: power verdubbelt met verviervoudiging van plots (logit schaal)
Vuistregel: <<<GEWOON RANDOM, CORRECTERE CIJFERS ZOEKEN>>> power verdubbelt met verachtvoudiging van bomen (logit schaal)
Vuistregel: power verdubbelt bij verdubbeling effect isze

```{r timesim}

calcsim <- function(n_plots, n_trees, 
                    maxd = 600, max_ppd = 4,
                    zoek = 15, commute = 120, between_plots = 50,
                    nnv = 5, sympt = 2
                    ) {
  timing <- data.frame(p1=NA, p2=NA, p3=NA, p4=NA, precisie=NA, 
                       maxperday = NA)
  for (ppd in 1:max_ppd) {
    maxperday <- 0
    timing_per_plot <- 
          ((zoek + (nnv + sympt) * n_trees) + 
          (commute/ppd + between_plots * (ppd-1)))
    timing_per_day <- ppd * timing_per_plot
    total_time <- n_plots * timing_per_plot
    maxperday <- ifelse(timing_per_day <= maxd, ppd, maxperday) 
    
    timing[1, "maxperday"] <- maxperday
    timing[1,ppd] <- timing_per_plot
  }
  timing[1, 1:max_ppd] <- n_plots * timing[1, 1:max_ppd]
  
  costfactor <- 1/sqrt(n_plots/100) * 1/((n_trees/20)**(1/3))
  timing[1, "precisie"] <- 1/costfactor
  timing
}

data <- expand.grid(plots = seq(15,150, by = 5),
                    trees = c(5,10,15,20,25,30))

calcs <- data %>% group_by(plots, trees) %>% 
  summarise(timings = calcsim(plots, trees))



```

--->