# Ontwerp van een meetnet met mixed effects model

## Inleiding

Omdat er geen specifieke doelstelling is, worden er verschillende analyses uitgewerkt.
Er worden 3 basisscenario's gebruikt:

- Standaard: een detectie van 12% verandering in 12 jaar, zoals in enkele andere meetnetten
- Een detectie van 20% verandering in 20 jaar
- Hoeveel verschil kan gedetecteerd worden in 2 opeenvolgende jaren.

In dit hoofdstuk leggen we uit wat er nodig is om de powerberekening uit te voeren en berekenen we welke instelwaarden relevant zijn voor de powerberekeningen.
De eigenlijke powerberekeningen komen aan bod in het volgende hoofdstuk.

### Modellen

De hele dataset kan worden gebruikt voor de modellen, waarbij elke individuele boom een observatie is in het meetnet en waarbij iedere afhankelijkheid tussen boom, proefvlak en tijd kan worden meegenomen.
Dit vergt echter enorm veel rekentijd voor weinig winst; daarom wordt uitgegaan van een vereenvoudigd model op data geaggregeerd op proefvlakniveau.

De impact van het aantal opgemeten bomen per proefvlak zal zich vooral laten gelden op de hoeveelheid variatie rond het proefvlakgemiddelde die verwacht wordt.
Een vierdeling van het aantal bomen leidt tot een halvering van de standaarddeviatie binnen de plot, omdat deze kwadratisch gerelateerd zijn.

In plaats van de veelgebruikte Mann-Kendall Tau-test, zoals vaak gebruikt door ICP Forests, wordt hier een lineair mixed effect model gekozen om de invloed van de steekproef op de trend te berekenen.
De focus ligt op het modelleren van de trend van gemiddeld bladverlies, in tegenstelling tot het berekenen van het aantal beschadigde bomen zoals vroeger.
Dit omdat toegenomen rekenkracht dit toelaat.

De huidige tijdreeks is bijna 40 jaar, dus het is niet relevant om lineaire trends te berekenen voor de hele periode. Daarom ligt de focus op een tijdvenster van 12 of 20 jaar.

Om de parameters voor het berekenen van het onderscheidend vermogen in te schatten, zal een rollend gemiddelde worden berekend over periodes van 12 jaar.
Het gemiddelde hiervan wordt gebruikt als basis voor een instelparameter voor de poweranalyse, en de bijbehorende standaarddeviatie zal bepalen welke scenario's relevant zijn om het onderscheidend vermogen voor te berekenen.

### Onderscheidend vermogen (Power)

Het onderscheidend vermogen van het meetnet wordt berekend door middel van simulatie om te bepalen hoe goed een scenario is ontworpen om een trend op te pikken over de soorten.
Voor een uitspraak per soort zal het onderscheidend vermogen lager zijn en zal voor elke soort afzonderlijk een ongeveer even groot meetnet nodig zijn als voor alle soorten samen.

In dit document, waarbij we alle data aggregeren per proefvlak, zullen volgende instelparameters belangrijk zijn om de power te berekenen:

- Aantal plots:  hoe meer plots, hoe meer nauwkeurig we bladverlies kunnen inschatten
- Aantal bomen per plot:  hoe meer bomen hoe nauwkeuriger de schatting per plot is
- Aantal jaren in het meetnet: Hoe langer het meetnet loopt, hoe fijner de trend ingeschat kan worden
- Gewenste te detecteren effectgrootte: een trend van 12% na 12 jaar is moeilijker te detecteren dan een trend van 20% na 20 jaar
- Variatie tussen plots: hoe minder verschillende plots verschillen, hoe nauwkeuriger het model
- Variatie binnen een plot in hetzelfde jaar: ook hier zal een kleinere variatie leiden  tot een nauwkeurigere inschatting. De variatie binnen een plot wordt bepaald door de variatie tussen de verschillende bomen in het plot. Hoe meer bomen hoe kleiner de variatie op de inschatting van het bladverlies op het plotniveau.
- Variatie  binnen een plot tussen verschillende jaren: hoe  hoger de autocorrelatie tussen opeenvolgende jaren hoe minder informatie de dataset bevat en hoe meer data nodig is voor eenzelfde uitspraak. <!--hvc of nog anders gezegd: hoe hoger de autocorrelatie hoe langer de tijdreeks moet zijn en hoe groter het tijdsverschil tussen twee jaren moet zijn om ze als onafhankelijk van elkaar te kunnen beschouwen. Is ook een argument pro belang van lange tijdreeks.-->

## Bepalen van de responsvariabele in het model

### Normale benadering

De data die we gaan gebruiken als basis voor conclusies is de volledige data van het bosvitaliteitsmeetnet vanaf het jaar 1995. In de jaren van 1987 tot 1994 waren er veel minder proefvlakken, dus deze data gaan we hier niet gebruiken omdat die veel minder representatief zijn voor het huidige meetnet.
Deze gereduceerde periode omvat nog steeds een tijdreeks van 28 jaar.

Omdat een normale verdeling voor een respons het gemakkelijkst en snelste werkt, wordt in eerste instantie onderzocht dat een normale benadering in het model acceptabel is.

In figuur \@ref(fig:verdelingbladverlies) blijkt dat eens een boom begint veel beschadiging te vertonen, dat de toestand sterk verslechterd, en dat er hierdoor heel weinig observaties zijn met een bladverlies hoger dan 50%. 
Dit op de dode bomen na, die 100% bladverliesscore krijgen. Deze verdwijnen echter een jaar na sterfte uit de dataset.
Een normale verdeling als benadering zal een onderschatting geven van de responsvariatie, maar relatief gezien gaat dit over heel weinig bomen die ook snel verdwijnen uit de steekproef.

```{r verdelingbladverlies, echo = FALSE, fig.cap="Range van de observaties in de ruwe data", warning = FALSE, message=FALSE}
library(tidyverse)
library(nlme)
library(lme4)
df_trees <- read_csv2("data/inputdata.csv") %>% 
  filter(!is.na(nnv),
         jaar >= 1995) %>% 
  mutate(jaarC = jaar - 2000, 
         prbo = paste(plot, tree, sep = "."))

df_plots <- df_trees %>% 
  group_by(plot, jaar) %>% 
  summarize(n_trees = n(), 
            sd_tree = sd(nnv),
            nnv =  mean(nnv), 
            se_resid = sd_tree / sqrt(n()),
            se_resid = ifelse(is.na(se_resid), se_resid, 0),
            .groups = "drop") %>% 
  filter(jaar >= 1995) %>% 
  mutate(plot = as.factor(plot),
         jaarC = jaar - 2000) %>% 
  na.omit()


ggplot(df_trees, aes(x = nnv)) + geom_histogram(binwidth = 0.05) + 
  xlab("Bladverlies") + ylab("Aantal")

```


Als naar de evolutie van het bladverlies over de jaren wordt gekeken in de ruwe dataset in figuur \@ref(fig:trendperjaar), dan is duidelijk dat er geen mooie lineaire trend is.
Daarentegen is er weinig verschil als de data per plot of per boom geaggregeerd wordt, behalve in de latere jaren.
Op 2 jaar na is dit verschil beperkt tot minder dan een halve procent, en de curves volgen ook een vergelijkbaar patroon. 
Dus vermoedelijk zal het aantal bomen en de variatie tussen de bomen binnen een plot niet veel impact hebben op de schattingen van het model.
Er wordt natuurlijk wel impact verwacht op de betrouwbaarheid van de schattingen van het proefvlakgemiddelde, die hoger is wanneer meer bomen per proefvlak gemeten worden.

```{r trendperjaar, fig.cap= "trend per jaar (zwart geaggregeerd per plot, groen gewoon naïef over alle bomen heen zonder rekening te houden met plot)", echo=FALSE}
  tr_plot <- df_plots %>% group_by(jaar) %>% 
    summarise(mean_nnv = mean(nnv), .groups = "drop")
  tr_tree <- df_trees %>% group_by(jaar) %>% 
    summarise(mean_nnv = mean(nnv), .groups = "drop")
  ggplot(data = tr_plot, aes(x = jaar, y = mean_nnv)) + 
    geom_point() + geom_line() + 
    geom_point(data = tr_tree, color = "green4") + 
    geom_line(data = tr_tree, color = "green4") +
    scale_y_continuous(labels = scales::percent) +
    ylab("Gemiddeld bladverlies")
```


Daarnaast is er veel verschil tussen de plots in figuur \@ref(fig:evolutieperplot).

```{r evolutieperplot, fig.cap = "Evolutie bladverlies geaggregeerd per plot. Groene lijn is gemiddeld bladverlies over de dataset", echo = FALSE}

ggplot(df_plots, aes(x = jaar, y = nnv, groups = plot)) + 
  geom_line() + 
  geom_hline(yintercept = mean(df_plots$nnv), color = "darkgreen", linewidth = 1) +
  theme(legend.position = "none") +
  scale_y_continuous(labels = scales::percent) +
  ylab("Aandeel bladverlies")

```


Omdat we in deze studie vooral geïnteresseerd zijn in trends over een periode van 12 jaar, zullen we voor de trendanalyses de modellen opsplitsen in rollende 12 jaar. Dat betekent dat we een model gaan fitten van 1995 tot en met 2007, een volgend model van 1996 tot en met 2008, enzovoort, tot en met 2010 tot en met 2022. Een inschatting van de variantieparameters zal dan gebeuren op basis van de resultaten van al deze modellen. De schattingen hiervan komen aan bod in het punt rond bepalen van correlaties. Deze berekende parameters worden ook gebruikt voor de modellen die de power voor kortere en langere tijdperiodes berekenen. Dus er is geen speciale betekenis van een rollend gemiddelde op 12 jaar, maar dit laat toe een nauwkeurigere schatting te maken ven de instelparameters, en ook een zicht te hebben hoe die variëren in de tijd.

<!--hvc ik vraag me af of het mogelijk is om het rollend gemiddelde te schatten op basis van één model op de volledige tijdreeks (jaar als factor) en dan predicties voor de jaren en hierop rollend gemiddelde berekenen -->

### Bepalen van het geschikte model

Voor dit meetnet is het zoals hogerop vermeld, niet mogelijk om een model te fitten op basis van het gehele datageneratieproces. De hoofdreden hiervoor is dat het over een heel grote dataset gaat met heel veel afhankelijkheden:

- Ieder plot zal een verschillende basisgezondheidstoestand hebben
- Ieder plot kan anders evolueren dan de globale trend
- Iedere boom in een plot kan anders reageren dan andere bomen in een plot
- Dezelfde bomen worden in de tijd gemeten, dus er is autocorrelatie tussen de metingen
- Er wordt een normale benadering gebruikt van de respons, omdat een poweranalyse anders veel te ingewikkeld wordt.

Hoewel de normale benadering over het algemeen vrij goed is, zal dit in extreme gevallen heel slecht capteren.

Er zijn veel invloedsfactoren die de trend drastisch kunnen beïnvloeden, zoals droogte en warmte in het voorjaar, stormschade en insectenschade, het al dan niet mastjaar zijn, antropogene invloeden zoals kappingen. Dit is ook een van de hoofdredenen dat een jaarlijkse meting aangewezen is. Indien geen jaarlijkse meting, kan je tot heel rare conclusies komen, als het ene jaar toevallig een warm mastjaar is en de meting 10 jaar later in een koud zaadarm jaar voorkomt.

Voor een meetnet kunnen we echter al deze variabelen niet in rekening brengen en mag enkel de jaarlijkse trend gebruikt worden als verklarende variabele. <!--hvc dat is een eerder strikte interpretatie van wat je met een meetnet mag. Zelf zie ik dat minder strikt.-->

#### Het model voor de volledige dataset

Het model dat het best aansluit bij het meetnetontwerp en data-generatief process, is te complex om te gebruiken voor een poweranalyse omdat het model moeilijk zal convergeren of meerdere uren zal moeten rekenen per iteratie:

$$
Bladverlies \sim 1 + Jaar + (Jaar | Plot / Boom) + ar(Exp_{n,r}(\sim Jaar | Plot / Boom))
$$

Deze formule modelleert het bladverlies aan een inschatting van een globaal gemiddelde (intercept `1+`) en een jaarlijkse trend (`Jaar`). Daarnaast kan de jaarlijkse trend verschillend zijn per proefvlak en per boom in het proefvlak (`Jaar|Plot/Boom`). Daarnaast is voor iedere boom in ieder plot, de meting van het huidige jaar, sterk gerelateerd aan de voorgaande jaren waarbij de correlatie afneemt met het aantal jaren verschil. Dit wordt opgevangen met een exponentiële autocorrelatie (`ar(...)`).

Als voorbeeld gebruiken we dit model hier om de trend te bepalen over de laatste periode van 12 jaar (2010 tem 2022). 
De autocorrelatieparameters zijn hier reeds ingevuld en werden apart bepaald.
Dit model is natuurlijk niet ideaal omdat er een grote stijging is in het bladverlies halverwege de jaren '10

Enkele anomalieën kunnen niet vermeden worden door de normale benadering, waardoor het bladverlies in een beperkt aantal gevallen boven de 100% wordt geschat, maar dit gaat over zo weinig datapunten dat dit niet echt een probleem is voor de conclusies.


```{r modeltest, eval = TRUE, echo = TRUE, cache = TRUE ,warning=FALSE, echo = FALSE}
library(nlme)
base_lme <- lme(nnv ~ jaarC, 
                random = ~ 1 + jaarC|plot/tree, 
                #correlation = corExp(form = ~jaar|plot/tree, nugget = TRUE),
                correlation = corExp(value = c(7, 0.14), nugget = TRUE, fixed = TRUE),
                data = df_trees %>% filter(jaar >= 2010), 
                control = lmeControl(maxiter = 100, 
                                     tolerance = 1e-4,
                                     opt = "optim",
                                     optimMethod = "L-BFGS-B"))
#summary(base_lme)

plotdata_full <- data.frame(
  fit = fitted(base_lme), 
  resid = resid(base_lme, type = "n"),
  jaar = df_trees %>% filter(jaar >= 2010) %>% pull(jaar))

  ggplot(plotdata_full, aes(x = fit, y = resid, color = jaar)) + 
  geom_point(pch = 1) + labs(x = "Gefitte waarden", 
                             y = "Genormaliseerde residu's", 
                             color = "Jaar")

```

```{r normaleverdeling, echo = FALSE, fig.cap="Residu's van het complexe model"}
    ggplot(plotdata_full, aes(x = resid)) + geom_histogram(binwidth = 0.25)
```
                                  

<!---
```{r modeltestx, echo = FALSE, eval = FALSE, include = FALSE}
base_lme2 <- lme(nnv ~ jaarC, 
                random = ~ 1 + jaarC|plot/tree, 
                #correlation = corExp(form = ~JaarC|PlotNr/BoomNr, nugget = TRUE),
                #correlation = corExp(value = c(7, 0.14), nugget = TRUE, fixed = TRUE),
                data = df_trees %>% filter(jaarC >= 0), 
                control = lmeControl(maxiter = 100, 
                                     tolerance = 1e-4,
                                     opt = "optim",
                                     optimMethod = "L-BFGS-B"))

base_lme3 <- lme(nnv ~ jaarC, 
                random = ~ 1 |plot/tree, 
                correlation = corExp(form = ~jaarC|plot/tree, nugget = TRUE),
                #correlation = corExp(value = c(7, 0.14), nugget = TRUE, fixed = TRUE),
                data = df_trees %>% filter(jaarC >= 0), 
                control = lmeControl(maxiter = 100, 
                                     tolerance = 1e-4,
                                     opt = "optim",
                                     optimMethod = "L-BFGS-B"))

cs1 <- corARMA(0.7, ~ jaarC | group, p = 1)

base_lme4 <- lme(nnv ~ jaarC, 
                random = ~ jaarC |plot/tree, 
                correlation = corARMA(c(0.9), 
                                      form = ~ jaarC | plot/tree, 
                                      p = 1, q = 0),
                data = df_trees %>% filter(jaarC >= 0), 
                control = lmeControl(maxiter = 100, 
                                     tolerance = 1e-4,
                                     opt = "optim",
                                     optimMethod = "L-BFGS-B"))

testdata <- df_trees %>% 
  filter(jaarC >= 0) %>% 
  select(jaarC, plot, tree, nnv)
testdata$residraw_noac <- resid(base_lme2)
testdata$resid_noac <- resid(base_lme2, type = "n")

testac <- gls(resid_noac ~ 1, data = testdata, 
            correlation = corExp(form = ~ jaarC | plot/tree, nugget = TRUE))


anova(base_lme, base_lme2, base_lme3, base_lme4)


base_tmb <- glmmTMB(nnv ~ jaarC  +
                      (jaarC|plot/tree) + 
                      exp(times  + 0 | group), 
                    data = df_trees %>% filter(jaarC >= 0))

resids <- data.frame(resn = resid(base_lme, type = "n")) %>% 
  mutate(qqprob = seq(0,1, length = n()),
         norm = qnorm(qqprob))
                     
ggplot(resids) + geom_density(aes(x = resn )) + 
  geom_density(aes(x = norm), color = "red")

#summary(base_lme)

```
--->

Op basis van bovenstaand plot \@ref(fig:verdelingbladverlies) blijkt dat de meeste bomen een bladverlies hebben onder de 50% en dat binnen het bereik 0-50% de verdeling er vrij normaal uit ziet. Om dit iets exacter te bekijken is er figuur \@ref(fig:normaleverdeling) waaruit blijkt dat het model (mixed effect model met fixed effect op Jaar en random effect PlotNr met daarin BoomNr genest) met een Gaussiaanse distributie een goede benadering geeft.

Dus ondanks enkele mogelijke artefacten aan de uiteinden 0% en > 50% zal een normale benadering bruikbaar zijn.


Om de power later te kunnen berekenen zullen we echter gebruik maken van een vereenvoudigd model, die wel wat impact zal hebben op de inschatting van de power maar toch probeert met alles zo goed mogelijk rekening te houden.

#### Eenvoudiger model

Hiervoor gaan we de data aggregeren op plotniveau.
Het effect van het aantal opgemeten bomen zal worden ondervangen door een kleinere variatie op de schatting van het bladverlies. Door 20 bomen te meten in plaats van 5, zal de schatting op de standaarddeviatie op het plotgemiddelde met factor 2 dalen.
Hierdoor is er ook geen autocorrelatie meer tussen verschillende bomen. De autocorrelatie tussen metingen van hetzelfde plot over verschillende jaren, gaan we opvangen door een random effect voor plot te gebruiken, want zelfs na 20 jaar blijft de correlatie vrij groot, veel groter dan nauwkeurig kan bekomen worden met een  afname van de correlatie over de tijd.

Daarnaast veronderstellen we ook dat alle bomen in eenzelfde plot dezelfde trend in de tijd volgen in plaats van elk een individuele trend.

Het vereenvoudigde model voor de powerberekeningen ziet er dan als volgt uit:

$$
Bladverlies \sim 1 + Jaar + (Jaar|Plot)
$$

Dus hier berekenen we een algemeen effect van jaar, maar laten we toe dat ieder plot een eigen trendlijn heeft met een eigen intercept en helling.
Volgende parameters worden berekend:

- globale intercept: het geschatte bladverlies in het jaar 0 (na centrering)
- globale helling op jaar: de gemiddelde helling die ieder plot volgt
- random intercept: de variatie van de afwijking van ieder plot in het jaar 0 ten opzichte van de globale intercept
- random helling op jaar: de variatie van de trend van ieder plot ten opzichte van de globale helling voor jaar
- correlatie tussen random intercept en random helling


```{r vereenvoudigdmodel, echo = FALSE, message=FALSE, warning = FALSE, message=FALSE, cache = TRUE}
library(lme4)
df_trees_agg <- df_trees %>% group_by(plot, jaar, jaarC) %>% 
  summarise(nnv = mean(nnv),
            sdw = sd(nnv) / sqrt(n()), 
            sdw = ifelse(is.na(sdw), 0, sdw))
model <- lmer(nnv ~ jaarC + (jaarC|plot) , 
              data = df_trees_agg %>% filter(jaar >= 2010))
#summary(model)
plotdata_red <- data.frame(
  fit = fitted(model), 
  resid = resid(model, type = "pe"),
  jaar = df_trees_agg %>% filter(jaar >= 2010) %>% pull(jaar))

  ggplot(plotdata_red, aes(x = fit, y = resid, color = jaar)) + 
  geom_point(pch = 1) + labs(x = "Gefitte waarden", 
                             y = "Genormaliseerde residu's", 
                             color = "Jaar")
  ggplot(plotdata_red, aes(x = resid)) + geom_histogram(binwidth = 0.0025)

#  e1 <- coef(summary(base_lme))
#  e2 <- coef(summary(model))
#  dt <- data.frame(model = c("base", "simpler"), 
#                   est = c(e1[2,1], e2[2,1]), 
#                   lcl = c(e1[2,1] - 2 * e1[2,2], e2[2,1] - 2 * e2[2,2]),
#                   ucl = c(e1[2,1] + 2 * e1[2,2], e2[2,1] + 2 * e2[2,2]))
# ggplot(dt, aes(x = model, y = est, ymin = lcl, ymax = ucl)) + 
#   geom_point() + geom_errorbar()

```

De schattingen tussen het ingewikkelde en vereenvoudigde model zijn compatibel met elkaar, en ook de standaardfout op de schatting van jaar is vergelijkbaar (ergens een 10% verschil), dus ook de power tussen beide modellen is hierdoor vergelijkbaar, omdat de power nu eenmaal bepaald wordt door de standaardfout, waardoor het eenvoudigere model gebruikt kan worden.

<!--hvc hier nog cross-ref toevoegen naar de twee figuren-->

## Inschatten van correlaties en variaties

Op basis van de dataset kunnen we zo goed mogelijke instelwaarden vinden om later een realistische poweranalyse uit te voeren.

## Inschattingen per soort

Als we naast een algemeen beeld over de soorten heen ook per soort een inschatting willen kunnen maken moet dit voor iedere soort apart in kaart  gebracht worden, wat we in dit document niet gaan doen. Maar op zich is dit vergelijkbaar met een meetnet met het aantal proefvlakken iedere soort te vinden is, als we aannemen dat de variatie van trend voor iedere soort vergelijkbaar is met over alle soorten heen

```{r soortenevaluatie, fig.cap = "Aantal plots waar de soort minstens 3 bomen beslaat", cache=TRUE, include = TRUE, message = FALSE, warning = FALSE, fig.width = 150/22.4}

voorkomen_soorten <- df_trees %>% 
  group_by(jaar, soort ) %>% 
  summarize(aantal = n()) %>% 
  arrange(jaar, desc(aantal))

voorkomen_tabel <- voorkomen_soorten %>% 
  pivot_wider(id_cols = jaar, names_from = soort, values_from = aantal) 


voorkomen_per_plot <- df_trees %>% 
  group_by(jaar, plot, soort) %>% 
  summarize(aantal = n(), .groups = "drop") %>% 
  mutate(three_or_more = aantal >= 3)

voorkomen_aantal_plots <- voorkomen_per_plot %>% 
  filter(aantal >= 3) %>% 
  group_by(jaar, soort) %>% 
  summarise(aantal_plots = n())


ggplot(voorkomen_aantal_plots %>% 
         filter(soort %in% c("Amerikaanse eik", "beuk", "Corsicaanse den", "es",
                             "esdoorn", "grove den", "ruwe berk", "zomereik")) , 
                aes(x = jaar, y = aantal_plots, color = soort)) +
  geom_line() + geom_point() + ylab("aantal proefvlakken") +
  geom_text(
    aes(x = 2022, label = soort),
    data = voorkomen_aantal_plots %>% 
      filter(soort %in% c("Amerikaanse eik", "beuk", "Corsicaanse den", "es",
                          "esdoorn", "grove den", "ruwe berk", "zomereik"),
             jaar == 2022), nudge_x = -1) +
  theme(legend.position = "none")
```




In figuur \@ref(fig:soortenevaluatie) is te zien per jaar in hoeveel plots een soort minstens 3 keer voorkomt. 



```{r inputmodels, echo = FALSE, eval = TRUE, cache = TRUE, results='hide', warning = FALSE, message = FALSE}

startjaren <- 1995:2010 
modellen <- simr_params <-  NULL
for (startjaar in startjaren) {
  jaren <- startjaar:(startjaar + 12)
  center <- median(jaren)
  print(startjaar)
  lmerdata <- df_trees_agg %>% filter(jaar %in% startjaar:(startjaar + 12)) %>% 
    mutate(jaarCC = jaar - center)
  model_calc <- 
    lmer(nnv ~ jaarCC + (jaarCC|plot), 
         data = lmerdata)
  
  #aangepast naar op basis van geaggregeerd model
  #sd_tree <- sqrt(VarCorr(model_calc)$prbo[1,1])
  sd_between_plots <- sqrt(VarCorr(model_calc)$plot[1,1])
  sd_trend_between_plots <- sqrt(VarCorr(model_calc)$plot[2,2])
  COV_plot <- VarCorr(model_calc)$plot
  COR_plot <- attr(VarCorr(model_calc)$plot, "correlation")
  correlation <- COR_plot[1,2]
  sd_resid <- attr(VarCorr(model_calc), "sc")
  simr <- list(
    #sd_tree = sd_tree, 
    sd_plot = sd_between_plots,
    sd_trend = sd_trend_between_plots,
    cor_trend_plot = correlation, 
    sd_resid = sd_resid, 
#   COV_tree = VarCorr(model_calc)$prbo,
    COV_plot = VarCorr(model_calc)$PlotNr)
  
  modellen[[startjaar-1994]] <- model_calc
  simr_params[[startjaar-1994]] <- simr
}


#voor een periode van 20 jaar
startjaren20 <- 1995:2002 

modellen <- simr_params20 <-  NULL
for (startjaar in startjaren20) {
  jaren <- startjaar:(startjaar + 20)
  center <- median(jaren)
  print(startjaar)
  lmerdata <- df_trees_agg %>% filter(jaar %in% startjaar:(startjaar + 20)) %>% 
    mutate(jaarCC = jaar - center)
  model_calc <- 
    lmer(nnv ~ jaarCC + (jaarCC|plot), 
         data = lmerdata)
  
  #aangepast naar op basis van geaggregeerd model
  #sd_tree <- sqrt(VarCorr(model_calc)$prbo[1,1])
  sd_between_plots <- sqrt(VarCorr(model_calc)$plot[1,1])
  sd_trend_between_plots <- sqrt(VarCorr(model_calc)$plot[2,2])
  COV_plot <- VarCorr(model_calc)$plot
  COR_plot <- attr(VarCorr(model_calc)$plot, "correlation")
  correlation <- COR_plot[1,2]
  sd_resid <- attr(VarCorr(model_calc), "sc")
  simr <- list(
    #sd_tree = sd_tree, 
    sd_plot = sd_between_plots,
    sd_trend = sd_trend_between_plots,
    cor_trend_plot = correlation, 
    sd_resid = sd_resid, 
#   COV_tree = VarCorr(model_calc)$prbo,
    COV_plot = VarCorr(model_calc)$plot)
  
  modellen[[startjaar-1994]] <- model_calc
  simr_params20[[startjaar-1994]] <- simr
}

```


### Inschatten variabiliteit tussen proefvlakken

Eerst bekijken we op basis van de ruwe data wat de variatie tussen de plots is.
We kijken over alle jaren sedert 1995 wat de standaarddeviatie van het bladverlies is tussen de plots in de data geaggregeerd per plot. Dit is te vinden in figuur \@ref(fig:sdbetweenplotsraw).

```{r sdbetweenplotsraw, echo = FALSE, fig.cap="Verdeling op basis van ruwe gegevens"}
sd_between_plots <- 
  df_plots %>%  
  group_by(jaar) %>% 
  summarise(sd_between_plots = sd(nnv))

sd_bp_avg <- mean(sd_between_plots$sd_between_plots)

ggplot(sd_between_plots, aes(x = sd_between_plots)) + 
  geom_density() + geom_vline(xintercept = sd_bp_avg, color = inbo_palette()[3]) + 
  xlab("standaarddeviatie tussen plots op basis vatn ruwe data") + ylab("densiteit")

#quantile(sd_between_plots, prob = c(0,0.10,0.25,0.50,0.75,0.90,1))
#mean(sd_between_plots)
#sd(sd_between_plots)
#hist(sd_between_plots)  
```

In een tweede methode, maken we een model op de geaggregeerde data per plot voor iedere rollende 13 (trend na 12 jaar: startjaar + 12 jaar) jaar beginnende vanaf 1995. Dus het eerste model is de periode 1995-2007, het tweede van 1996-2008 tot tenslotte 2010-2022. De resultaten hiervan staan in figuur  \@ref(fig:sdbetweenplotsmodel).

De variatie tussen al deze modellen zullen een inzicht geven op wat te verwachten is van de standdaarddeviatie tussen de plots. Hiervoor wordt de random intercept schatting gebruikt. Als model gebruiken we het vereenvoudigde model zoals hogerop beschreven. Voor iedere dataset van 13 jaar, centreren we jaar in het midden van iedere 13 jaar, dus de dataset die in 1995 begint wordt gecentreerd op 2001, die in 1996 op 2002, enz ... 

```{r sdbetweenplotsmodel, echo = FALSE, dependson="inputmodels", fig.cap="Verdeling geschatte random intercept op plotniveau als het model over een rollende 13 jaar gefit wordt"}

startjaren <- 1995:2010
df_bp <- data.frame(
  startjaar = startjaren, 
  sd_between_plots = sapply(simr_params, function(x) x$sd_plot))

sd_bp_chosen <- 0.07

ggplot(df_bp, aes(x = startjaar, y = sd_between_plots)) + geom_point() +
  ylab("standaarddeviatie tussen plots")

```

Voor de eerdere periodes is dit vrij stabiel rond 0.045, maar daarna stijgt de variatie tussen plots geleidelijk, om de laatste jaren weer af te vlakken naar ca 0.065 - 0.07.
Vermoedelijk is dit door introductie van nieuwe plots en het verouderen van de bestaande plots. Als consensusparameter voor de standaarddeviatie tussen plots gebruiken we `r sd_bp_chosen`.


### Inschatten variabiliteit tussen bomen in eenzelfde proefvlak




```{r sdbetweentreesraw, echo = FALSE, fig.cap="Verdeling standaarddeviatie tussen bomen in een plot op basis van de ruwe data." }

sd_between_trees <- df_trees %>% 
  group_by(plot, tree, jaar) %>% 
    summarise(sd_between_trees = mean(nnv))

sd_bt_avg <- mean(sd_between_trees$sd_between_trees)

ggplot(sd_between_trees, aes(x = sd_between_trees)) + 
  geom_histogram(binwidth = 0.05) + 
  geom_vline(xintercept = sd_bt_avg, color = inbo_palette()[3]) + 
  xlab("standaarddeviatie over bomen in een plot") + ylab("aantal")

```

Om de variabiliteit tussen bomen in een proefvlak te onderzoeken wordt op dezelfde manier te werk gegaan als voor de variabiliteit tussen plots, eerst op basis van de ruwe data (figuur \@ref(fig:sdbetweentreesraw) ) en daarna op basis van dezelfde modellen als bij de proefvlakken \@ref(fig:sdbetweentreesmodel) ).

```{r sdbetweentreesmodel, echo = FALSE, fig.cap="Verdeling standaarddeviatie tussen bomen in een plot op basis van het vooropgestelde model."}
df_bt <- data.frame(
  startjaar = startjaren, 
  sd_between_trees = sapply(simr_params, function(x) x$sd_resid))

sd_bt_chosen <- 0.036 * sqrt(24) 
sd_bt_chosen <- 0.175

ggplot(df_bt, aes(x = startjaar, y = sd_between_trees)) + geom_point() + 
  ylab("standaarddeviatie over bomen in een plot")

```

Ook hier is de inschatting verschillend voor verschillende startjaren van het model, toch blijft dit vrij beperkt tussen 0.034 en 0.038 (aangezien er ongeveer 24  bomen per plot zijn is 0.036 * sqrt(24) ongeveer hetzelfde als de 0.175 als uit de ruwe data gehaald wordt).
 Als consensusparameter voor de variabiliteit tussen de bomen gebruiken we `r sd_bt_chosen`.


### Inschatten van de variabiliteit van de trends tussen de plots

Voor de inschatting van de random helling die ieder plot volgt rond de globale trend wordt op een vergelijkbare manier als voor de andere parameters gewerkt.
De modellen tonen nu de inschatting van de random helling tussen de plots (figuur \@ref(fig:sdtrendmodel) ).

```{r sdtrendmodel, echo = FALSE, fig.cap="Variatie van de trends per plot"}

sd_trend <- data.frame(
  periode = "over 12 jaar",
  startjaar = startjaren, 
  sd_trend = sapply(simr_params, function(x) x$sd_trend))

sd_trend_chosen <- 0.0065


sd_trend20 <- data.frame(
  periode = "over 20 jaar",
  startjaar = startjaren20,
  sd_trend = sapply(simr_params20, function(x) x$sd_trend))

ggplot(bind_rows(sd_trend, sd_trend20), 
       aes(x = startjaar, y = sd_trend, color = periode)) + geom_point() + 
  ylab("standaardafwijking van de hellingen tussen de plots")


```

De standaardafwijking op de trend is voor de middelste startjaren heel wat sterker dan de rest. Dit heeft veel te maken met de extreme stijgiging in bladverlies in de jaren 2011 en 2012. In de latere jaren wordt de invloed van deze jaren veel minder en zwakt de standaardafwijking tussen de trend terug af. Als instelwaarde gebruiken we `r sd_trend_chosen`. Als de variabiliteit op de trend over 20 jaar wordt bekeken is die wat lager, wat erop wijst dat de plots over lange tijd minder afwijken van de globale trend. Toch is dit verschil vrij klein en mogelijk niet relevant.

### Inschatten van correlatie tussen random intercept van plot met trend per plot

```{r correlatietrndplot, echo = FALSE, fig.cap="Verdeling correlaties tussen random trend en random intercept"}
cor_slope <- data.frame(
  startjaar = startjaren, 
  cor_slope = sapply(simr_params, function(x) x$cor_trend_plot))

cor_chosen <- 0.40

ggplot(cor_slope, aes(x = startjaar, y = cor_slope)) + geom_point()
```

Ook hier is een groot verschil tussen modellen met de beginjaren en de modellen die de middelste jaren gebruiken (figuur \@ref(fig:correlatietrndplot) ). Omdat correlatie tussen random trend en intercept belangrijk kunnen zijn, gaan we hier eerder een worst-case scenario gebruiken, en gebruiken we als instelwaarde `r cor_chosen`.

<!--hvc één van de figuren in pdf is de y-as titel deels afgeknipt. Dus best fig.height aanpassen of een \n in de titel zetten-->

### Inschatting autocorrelatie op plotniveau

```{r autocorplot, fig.cap="Correlatie in de tijd"}
df2 <- df_trees_agg %>% 
  group_by(plot, jaar) %>% 
  summarise(avg = mean(nnv), .groups = "drop") %>% 
  mutate(avg0 = avg, 
         J0 = jaar, J1 = jaar - 1, J2 = jaar - 2, J3 = jaar - 3,
         J4 = jaar - 4, J5 = jaar - 5, J6 = jaar - 6, J7 = jaar - 7, 
         J8 = jaar - 8, J9 = jaar - 9, J10 = jaar - 10,
         J11 = jaar -11, J12 = jaar - 12)

df2m <- df2 %>% 
  inner_join(df2 %>% select(J1, avg1 = avg, plot),
             by = c("J0" = "J1", "plot")) %>% 
  inner_join(df2 %>% select(J2, avg2 = avg, plot),
             by = c("J0" = "J2", "plot")) %>% 
    inner_join(df2 %>% select(J3, avg3 = avg, plot),
             by = c("J0" = "J3", "plot")) %>% 
    inner_join(df2 %>% select(J4, avg4 = avg, plot),
             by = c("J0" = "J4", "plot")) %>% 
    inner_join(df2 %>% select(J5, avg5 = avg, plot),
             by = c("J0" = "J5", "plot")) %>% 
    inner_join(df2 %>% select(J6, avg6 = avg, plot),
             by = c("J0" = "J6", "plot")) %>% 
    inner_join(df2 %>% select(J7, avg7 = avg, plot),
             by = c("J0" = "J7", "plot")) %>% 
    inner_join(df2 %>% select(J8, avg8 = avg, plot),
             by = c("J0" = "J8", "plot")) %>% 
    inner_join(df2 %>% select(J9, avg9 = avg, plot),
             by = c("J0" = "J9", "plot")) %>% 
    inner_join(df2 %>% select(J10, avg10 = avg, plot),
             by = c("J0" = "J10", "plot")) %>% 
    inner_join(df2 %>% select(J11, avg11 = avg, plot),
             by = c("J0" = "J11", "plot")) %>% 
    inner_join(df2 %>% select(J12, avg12 = avg, plot),
             by = c("J0" = "J12", "plot"))

y2ydev <- c(sd(df2m$avg0 - df2m$avg1), 
            sd(df2m$avg1 - df2m$avg2), 
            sd(df2m$avg2 - df2m$avg3),
            sd(df2m$avg3 - df2m$avg4), 
            sd(df2m$avg4 - df2m$avg5),
            sd(df2m$avg5 - df2m$avg6), 
            sd(df2m$avg6 - df2m$avg7),
            sd(df2m$avg7 - df2m$avg8),
            sd(df2m$avg8 - df2m$avg9), 
            sd(df2m$avg9 - df2m$avg10),
            sd(df2m$avg10 - df2m$avg11), 
            sd(df2m$avg11 - df2m$avg12))
#mean(y2ydev)
#sd(y2ydev)

get_cor_per_lag <- function(cormat, lag = 1, return_vec = TRUE) {
  rv <- NULL
  for (l in lag) {
    #cat("lag is:", l, "\n")
    xpos <- 1:(nrow(cormat) - l)
    ypos <- xpos + l
    #print(xpos)
    #print(ypos)
    for(i in xpos) {
      rv <-  bind_rows(rv,  data.frame(lag = l, cor = cormat[xpos[i], ypos[i]]))     
    }    
  }
  rv
}
            
cormat <- cor(df2m[c("avg0", "avg1", "avg2", "avg3", "avg4", "avg5", "avg6",
                     "avg7", "avg8", "avg9", "avg10", "avg11", "avg12")])

lags <- 1:12 #best fit met 1:12 en corstruct_exp
corrs <- get_cor_per_lag(cormat, lag = lags)
corrs2 <- corrs %>% group_by(lag) %>% summarize(cor = mean(cor))

corstruct_exp <- nls(formula = cor ~ (1-n) * exp(-lag/d), 
                     data = corrs, 
                     start = list(n = 0.2, d = 7))

preds <- data.frame(lag = lags, 
                    fit1 = predict(corstruct_exp, 
                                   newdata = data.frame(lag = lags)))

ggplot(corrs, aes(x = lag, y = cor)) + geom_point() + 
  geom_line(data = preds, aes(y = fit1))


```

Rekening houden met autocorrelatie zorgt dat modellen fitten heel ingewikkeld worden. Daarom dat voor de poweranalyse deze niet expliciet meegerekend zal worden. Er wordt echter wel een impliciete correlatie tussen metingen van eenzelfde plot in rekening gebracht, omdat een random intercept op plotniveau wel in het model opgenomen is. Het verschil tussen een autocorrelatie door een random intercept geïmpliceerd en een autocorrelatie is dat bij een random effect de correlatie even hoog verondersteld wordt ongeacht hoeveel jaren er verstreken zijn, in tegenstelling tot een tijdsvariërende autocorrelatie.

Omdat de autocorrelatie ook na 12 jaar nog vrij hoog is, zal een random intercept zonder autocorrelatie toch nog een vrij goede benadering zijn.

<!--
## Dimensionering meetnet op soortniveau

### Soortenkeuze

Enkel soorten die ieder jaar in minstens 5 plots voorkomen en in die plots minstens 3 bomen hebben worden beschouwd als relevant. 

### Voorkomen van soorten in dataset

```{r soortenbis}
# soorten_behouden <- ieder_jaar_5_plots %>% 
#   filter(min_aantal_plots >= 5) %>% 
#   pull(soort)
# 
# sd_all <- df_trees %>% 
#   group_by(jaar, plot) %>% 
#   summarise(Soort = "allemaal", sds = sd(nnv))
# summary(sd_all$sds)
# 
# sd_spec <- df_trees %>% 
#   filter(soort %in% soorten_behouden) %>% 
#   group_by(jaar, soort, plot) %>% 
#   summarise(sds = sd(nnv))
# 
# sds <- bind_rows(sd_all, sd_spec)

# knitr::kable(ieder_jaar_5_plots)
# ggplot(sds, aes(x = sds)) + geom_histogram() + 
#   geom_vline(data = sds %>% 
#                group_by(soort) %>% 
#                summarise(median = median(sds, na.rm = TRUE)), 
#              aes(xintercept = median), color = "red") +
#   facet_wrap(~soort, ncol = 1, scales = "free_y")

```


De variatie tussen bomen in een plot is in dezelfde grootte-orde wanneer alle bomen tegelijk beschouwd worden of per belangrijke soort apart. Dit wil zeggen dat de conclusies voor alle soorten samen doorgetrokken kunnen worden naar de belangrijke soorten apart. Het heeft geen zin om uitspraken te doen over soorten die te weinig voorkomen in de dataset.

--->




